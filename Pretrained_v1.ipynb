{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "\n",
    "How to run this notebook on, say Google Colab :\n",
    "\n",
    "1. Upload this Notebook to Colab. Upload the file imagenet_classes.txt as well (Menu on Left >> FILES >> Upload)\n",
    "2. Upload a few sample images as well to Colab (Menu on Left >> FILES >> Upload)\n",
    "3. Run this Notebook Cell by Cell. Make sure you have correct paths defined.\n",
    "4. If Google Colab doesn't have the package, you would have to install it.\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "All imports\n",
    "\n",
    "'''\n",
    "\n",
    "from torchvision import models\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Using some super basic transformations of images. Just a start, I am sure there is room for so much more\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([            \n",
    " transforms.Resize(256),                    \n",
    " transforms.CenterCrop(224),                \n",
    " transforms.ToTensor(),                     \n",
    " transforms.Normalize(                      \n",
    " mean=[0.485, 0.456, 0.406],                \n",
    " std=[0.229, 0.224, 0.225]                  \n",
    " )])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "\n",
    "Note : With this crude code, I am passing images one by one with hardcoding below. Feel free to improve this\n",
    "\n",
    "'''\n",
    "\n",
    "img = Image.open(\"./Data/site002_sd008_spring2019/site002_sd008_spring2019_148.JPG\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Just in case you want to check the imported image from above step. Uncomment below and run this cell'''\n",
    "#img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Transform the image and unsqueeze\n",
    "'''\n",
    "\n",
    "img_t = transform(img)\n",
    "batch_t = torch.unsqueeze(img_t, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "\n",
    "We would be using Imagenet classes. Image net classed all saved in ./imagenet_classes.txt at same path as \n",
    "this notebook in github\n",
    "\n",
    "'''\n",
    "\n",
    "with open('imagenet_classes.txt') as f:\n",
    "  labels = [line.strip() for line in f.readlines()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1000])\n"
     ]
    }
   ],
   "source": [
    "'''Trying Alexnet'''\n",
    "\n",
    "alexnet = models.alexnet(pretrained=True)\n",
    "alexnet.eval()\n",
    "out = alexnet(batch_t)\n",
    "print(out.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mountain bike, all-terrain bike, off-roader 8.19660758972168\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Generating a Prediction w/ Probabilty Score. The output class labels from imagenet classes.\n",
    "\n",
    "'''\n",
    "\n",
    "_, index = torch.max(out, 1)\n",
    "percentage = torch.nn.functional.softmax(out, dim=1)[0] * 100\n",
    "print('Image Classified as : ',labels[index[0]], 'with probability = ', percentage[index[0]].item(), ' %')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "\n",
    "Observations and Hypothesis - Given some of my test runs, I observe the following:\n",
    "\n",
    "1. If the image has no animals in it, Resnet's top predictions are inanimate things such as valleys, cliff, etc.\n",
    "2. If there are deer(s), Resnet's top prediction are indeed animal names such as gazelle.\n",
    "\n",
    "This is interesting because, the very objective of this stage is to separate out images w/o animals from images w/ \n",
    "animals. We really don't care if imagenet thinks a deer is a gazelle, as long as it detects that there are indeed \n",
    "animals in an image.\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "\n",
    "This is just very crude code and we need to:\n",
    "\n",
    "1. Refine the Code and make it more robust and able to run through a list of images and generate a report\n",
    "2. More thorough testing. As long as we are doing well (detect images with actual animals) with the 2GB odd worth \n",
    "of images that we already have, we can be pretty confident that it will work well on the entire exhaustive image\n",
    "bank. We can just create a working version of the code and let Tatum do some testing at her end.\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Now we will try a different pre-trained network e.g. Resnet\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Resnet seems to be better'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('valley, vale', 33.784912109375),\n",
       " ('alp', 28.378131866455078),\n",
       " ('mountain bike, all-terrain bike, off-roader', 6.858148574829102),\n",
       " ('cliff, drop, drop-off', 5.214917182922363),\n",
       " ('maze, labyrinth', 4.174210071563721)]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the pre-trained model\n",
    "resnet = models.resnet101(pretrained=True)\n",
    " \n",
    "# Switch to eval mode\n",
    "resnet.eval()\n",
    " \n",
    "# Score the Image\n",
    "out = resnet(batch_t)\n",
    " \n",
    "# Output top 5 classes predicted by the model\n",
    "_, indices = torch.sort(out, descending=True)\n",
    "percentage = torch.nn.functional.softmax(out, dim=1)[0] * 100\n",
    "[(labels[idx], percentage[idx].item()) for idx in indices[0][:5]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['AlexNet',\n",
       " 'DenseNet',\n",
       " 'Inception3',\n",
       " 'ResNet',\n",
       " 'SqueezeNet',\n",
       " 'VGG',\n",
       " '__builtins__',\n",
       " '__cached__',\n",
       " '__doc__',\n",
       " '__file__',\n",
       " '__loader__',\n",
       " '__name__',\n",
       " '__package__',\n",
       " '__path__',\n",
       " '__spec__',\n",
       " 'alexnet',\n",
       " 'densenet',\n",
       " 'densenet121',\n",
       " 'densenet161',\n",
       " 'densenet169',\n",
       " 'densenet201',\n",
       " 'inception',\n",
       " 'inception_v3',\n",
       " 'resnet',\n",
       " 'resnet101',\n",
       " 'resnet152',\n",
       " 'resnet18',\n",
       " 'resnet34',\n",
       " 'resnet50',\n",
       " 'squeezenet',\n",
       " 'squeezenet1_0',\n",
       " 'squeezenet1_1',\n",
       " 'vgg',\n",
       " 'vgg11',\n",
       " 'vgg11_bn',\n",
       " 'vgg13',\n",
       " 'vgg13_bn',\n",
       " 'vgg16',\n",
       " 'vgg16_bn',\n",
       " 'vgg19',\n",
       " 'vgg19_bn']"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "\n",
    "Note - Please try some more pretrained networks available in torchvision. A full list available in CHPC is below.\n",
    "When you import torch in google Colab, it might have a slightly different list of available Models\n",
    "\n",
    "'''\n",
    "\n",
    "dir(models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
